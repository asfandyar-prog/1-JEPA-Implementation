{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install timm\n\nimport torch, random, math\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:51.152673Z","iopub.execute_input":"2026-02-08T03:40:51.152998Z","iopub.status.idle":"2026-02-08T03:40:54.581678Z","shell.execute_reply.started":"2026-02-08T03:40:51.152963Z","shell.execute_reply":"2026-02-08T03:40:54.580766Z"}},"outputs":[{"execution_count":193,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":193},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n])\n\ntrain_ds = datasets.CIFAR10(root=\".\", train=True, download=True, transform=transform)\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n\nimgs, labels = next(iter(train_loader))\nimgs.shape, labels.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:54.583485Z","iopub.execute_input":"2026-02-08T03:40:54.583919Z","iopub.status.idle":"2026-02-08T03:40:55.755688Z","shell.execute_reply.started":"2026-02-08T03:40:54.583887Z","shell.execute_reply":"2026-02-08T03:40:55.754850Z"}},"outputs":[{"execution_count":194,"output_type":"execute_result","data":{"text/plain":"(torch.Size([32, 3, 224, 224]), torch.Size([32]))"},"metadata":{}}],"execution_count":194},{"cell_type":"code","source":"GRID=14\n\ndef sample_block_mask(grid=14,scale=(0.15,0.20),aspect=(0.75,1.5)):\n    area= grid*grid\n    target_area=random.uniform(*scale) * area\n    asp=random.uniform(*aspect)\n\n\n    h=int(round(math.sqrt(target_area * asp)))\n    w=int(round(math.sqrt(target_area/asp)))\n    h=max(1,min(grid,h))\n    w=max(1,min(grid,w))\n\n\n    top=random.randint(0,grid-h)\n    left=random.randint(0,grid-w)\n    mask=torch.zeros(grid,grid,dtype=torch.bool)\n    mask[top:top+h,left:left+w] = True\n\n    return mask\n\n\n\ndef sample_context_mask(grid=14,scale=(0.85,1.0)):\n    area= grid*grid\n    ctx_area=random.uniform(*scale)*area\n    side=int(round(math.sqrt(ctx_area)))\n    side=max(1,min(grid,side))\n\n\n    top=random.randint(0,grid-side)\n    left=random.randint(0,grid-side)\n\n    mask=torch.zeros(grid,grid,dtype=torch.bool)\n    mask[top:top+side,left:left+side]=True\n    return mask\n\n\ndef remove_overlap(ctx_mask, target_masks):\n    for tm in target_masks:\n        ctx_mask = ctx_mask & (~tm)\n    return ctx_mask\n\ndef mask_to_idx(mask2d):\n    return torch.where(mask2d.flatten())[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.757206Z","iopub.execute_input":"2026-02-08T03:40:55.757999Z","iopub.status.idle":"2026-02-08T03:40:55.766178Z","shell.execute_reply.started":"2026-02-08T03:40:55.757934Z","shell.execute_reply":"2026-02-08T03:40:55.765293Z"}},"outputs":[],"execution_count":195},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"M = 4\ntargets = [sample_block_mask(GRID) for _ in range(M)]\nctx = sample_context_mask(GRID)\nctx = remove_overlap(ctx, targets)\n\nctx_idx = mask_to_idx(ctx)\ntgt_idx = mask_to_idx(torch.stack(targets).any(dim=0))\n\nctx_idx.numel(), tgt_idx.numel()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.768418Z","iopub.execute_input":"2026-02-08T03:40:55.768768Z","iopub.status.idle":"2026-02-08T03:40:55.782995Z","shell.execute_reply.started":"2026-02-08T03:40:55.768740Z","shell.execute_reply":"2026-02-08T03:40:55.782331Z"}},"outputs":[{"execution_count":196,"output_type":"execute_result","data":{"text/plain":"(123, 73)"},"metadata":{}}],"execution_count":196},{"cell_type":"markdown","source":"**Minimal ViT encode**","metadata":{}},{"cell_type":"code","source":"class TinyViT(nn.Module):\n    def __init__(self, dim=256, depth=4, heads=8):\n        super().__init__()\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=dim,\n            nhead=heads,\n            batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(encoder_layer, depth)\n\n    def forward(self, x):\n        # x: [B, N, D]\n        return self.encoder(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.783913Z","iopub.execute_input":"2026-02-08T03:40:55.784219Z","iopub.status.idle":"2026-02-08T03:40:55.794362Z","shell.execute_reply.started":"2026-02-08T03:40:55.784188Z","shell.execute_reply":"2026-02-08T03:40:55.793671Z"}},"outputs":[],"execution_count":197},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Patch embedding**","metadata":{}},{"cell_type":"code","source":"class PatchEmbed(nn.Module):\n    def __init__(self,img_size=224,patch=16,dim=256):\n        super().__init__()\n        self.grid=img_size // patch\n        self.proj=nn.Conv2d(3,dim,kernel_size=patch,stride=patch)\n\n\n    def forward(self,x):\n        x=self.proj(x)\n        x=x.flatten(2).transpose(1,2)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.795146Z","iopub.execute_input":"2026-02-08T03:40:55.795354Z","iopub.status.idle":"2026-02-08T03:40:55.802512Z","shell.execute_reply.started":"2026-02-08T03:40:55.795323Z","shell.execute_reply":"2026-02-08T03:40:55.801960Z"}},"outputs":[],"execution_count":198},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Build student / teacher / predictor**","metadata":{}},{"cell_type":"code","source":"patch_embed = PatchEmbed().to(device)\ncontext_encoder = TinyViT(dim=DIM).to(device)\ntarget_encoder  = TinyViT(dim=DIM).to(device)\npredictor       = TinyViT(dim=DIM).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.803483Z","iopub.execute_input":"2026-02-08T03:40:55.803799Z","iopub.status.idle":"2026-02-08T03:40:55.904694Z","shell.execute_reply.started":"2026-02-08T03:40:55.803777Z","shell.execute_reply":"2026-02-08T03:40:55.903874Z"}},"outputs":[],"execution_count":199},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(\n    list(context_encoder.parameters()) +\n    list(predictor.parameters()),\n    lr=1e-4,\n    weight_decay=1e-4\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.905803Z","iopub.execute_input":"2026-02-08T03:40:55.906137Z","iopub.status.idle":"2026-02-08T03:40:55.912436Z","shell.execute_reply.started":"2026-02-08T03:40:55.906109Z","shell.execute_reply":"2026-02-08T03:40:55.911776Z"}},"outputs":[],"execution_count":200},{"cell_type":"markdown","source":"**Freeze Teacher**","metadata":{}},{"cell_type":"code","source":"for p in target_encoder.parameters():\n    p.requires_grad=False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.913488Z","iopub.execute_input":"2026-02-08T03:40:55.913742Z","iopub.status.idle":"2026-02-08T03:40:55.925085Z","shell.execute_reply.started":"2026-02-08T03:40:55.913720Z","shell.execute_reply":"2026-02-08T03:40:55.924292Z"}},"outputs":[],"execution_count":201},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Mask Tokens**","metadata":{}},{"cell_type":"code","source":"mask_tokens=nn.Parameter(torch.zeros(1,1,DIM))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.927805Z","iopub.execute_input":"2026-02-08T03:40:55.928197Z","iopub.status.idle":"2026-02-08T03:40:55.935518Z","shell.execute_reply.started":"2026-02-08T03:40:55.928169Z","shell.execute_reply":"2026-02-08T03:40:55.935002Z"}},"outputs":[],"execution_count":202},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Forward pass sanity check**","metadata":{}},{"cell_type":"code","source":"B=2\ndummy_img=torch.randn(B,3,224,224)\n\ntokens=patch_embed(dummy_img.device)\nprint(\"All Tokens: \",tokens.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:43:20.819883Z","iopub.execute_input":"2026-02-08T03:43:20.820230Z","iopub.status.idle":"2026-02-08T03:43:20.838071Z","shell.execute_reply.started":"2026-02-08T03:43:20.820200Z","shell.execute_reply":"2026-02-08T03:43:20.836901Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2692665776.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdummy_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All Tokens: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/981462660.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n","\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (torch.device, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!torch.device!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!torch.device!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n"],"ename":"TypeError","evalue":"conv2d() received an invalid combination of arguments - got (torch.device, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!torch.device!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!torch.device!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n","output_type":"error"}],"execution_count":204},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Context-only tokens**","metadata":{}},{"cell_type":"code","source":"ctx_tokens=tokens[:,ctx_idx]\nprint(\"Context tokens: \",ctx_tokens.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.955363Z","iopub.status.idle":"2026-02-08T03:40:55.955610Z","shell.execute_reply.started":"2026-02-08T03:40:55.955490Z","shell.execute_reply":"2026-02-08T03:40:55.955505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"M = 4\ntarget_masks = [sample_block_mask(GRID) for _ in range(M)]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.956603Z","iopub.status.idle":"2026-02-08T03:40:55.956822Z","shell.execute_reply.started":"2026-02-08T03:40:55.956717Z","shell.execute_reply":"2026-02-08T03:40:55.956729Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Target tokens (teacher)**","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    target_repr=target_encoder(tokens)\n    target_repr=target_repr[:,tgt_idx]\nprint(\"Target Repr: \",target_repr.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.957769Z","iopub.status.idle":"2026-02-08T03:40:55.958820Z","shell.execute_reply.started":"2026-02-08T03:40:55.958680Z","shell.execute_reply":"2026-02-08T03:40:55.958697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_target_repr(encoder_outputs, target_masks):\n    \"\"\"\n    encoder_outputs: [B, N, D]\n    target_masks: list of [grid, grid] boolean masks\n    \"\"\"\n    B, N, D = encoder_outputs.shape\n    grid = int(N ** 0.5)\n\n    outputs = []\n    for mask in target_masks:\n        flat_mask = mask.flatten()          # [N]\n        selected = encoder_outputs[:, flat_mask, :]  # [B, num_patches, D]\n        outputs.append(selected)\n\n    # concatenate all target blocks\n    return torch.cat(outputs, dim=1)        # [B, total_targets, D]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.959731Z","iopub.status.idle":"2026-02-08T03:40:55.960041Z","shell.execute_reply.started":"2026-02-08T03:40:55.959858Z","shell.execute_reply":"2026-02-08T03:40:55.959876Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Predictor input**","metadata":{}},{"cell_type":"code","source":"mask_tokens=mask_tokens.expand(B,tgt_idx.numel(),DIM)\npred_input=torch.cat([ctx_tokens,mask_tokens],dim=1)\nprint(\"Predictor Input : \",pred_input.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.961035Z","iopub.status.idle":"2026-02-08T03:40:55.961253Z","shell.execute_reply.started":"2026-02-08T03:40:55.961147Z","shell.execute_reply":"2026-02-08T03:40:55.961160Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Predictor Output**","metadata":{}},{"cell_type":"code","source":"pred_out=predictor(pred_input)\npredicted_targets=pred_out[:,-tgt_idx.numel():]\n\nprint(\"Predicted Targets: \",predicted_targets.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.962033Z","iopub.status.idle":"2026-02-08T03:40:55.962409Z","shell.execute_reply.started":"2026-02-08T03:40:55.962194Z","shell.execute_reply":"2026-02-08T03:40:55.962234Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**L2 loss (the learning signal)**","metadata":{}},{"cell_type":"code","source":"pred_targets = predictor(ctx_tokens)\n\nT_pred = pred_targets.shape[1]\nT_tgt  = target_repr.shape[1]\nT = min(T_pred, T_tgt)   # ðŸ”‘ critical line\n\npred_targets = pred_targets[:, :T, :]\ntarget_repr  = target_repr[:, :T, :]\n\nloss = ((pred_targets - target_repr) ** 2).mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.964020Z","iopub.status.idle":"2026-02-08T03:40:55.964386Z","shell.execute_reply.started":"2026-02-08T03:40:55.964204Z","shell.execute_reply":"2026-02-08T03:40:55.964224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Backprop (ONLY through context + predictor)**","metadata":{}},{"cell_type":"code","source":"optimizer.zero_grad()\nloss.backward()\noptimizer.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.965493Z","iopub.status.idle":"2026-02-08T03:40:55.965821Z","shell.execute_reply.started":"2026-02-08T03:40:55.965659Z","shell.execute_reply":"2026-02-08T03:40:55.965678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**EMA update**","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef ema_update(target, online, momentum=0.996):\n    for p_t, p_o in zip(target.parameters(), online.parameters()):\n        p_t.data = momentum * p_t.data + (1 - momentum) * p_o.data\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.966719Z","iopub.status.idle":"2026-02-08T03:40:55.967102Z","shell.execute_reply.started":"2026-02-08T03:40:55.966887Z","shell.execute_reply":"2026-02-08T03:40:55.966909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ema_update(target_encoder, context_encoder)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.968440Z","iopub.status.idle":"2026-02-08T03:40:55.968796Z","shell.execute_reply.started":"2026-02-08T03:40:55.968612Z","shell.execute_reply":"2026-02-08T03:40:55.968634Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Sanity Check:**   \n\nWe want to verify one thing only:\n\nDoes the loss go down over a few steps?\n\nIf it doesnâ€™t â†’ something is fundamentally wrong.\nIf it does â†’ JEPA is working.\n","metadata":{}},{"cell_type":"code","source":"y_full=tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.970240Z","iopub.status.idle":"2026-02-08T03:40:55.970586Z","shell.execute_reply.started":"2026-02-08T03:40:55.970415Z","shell.execute_reply":"2026-02-08T03:40:55.970436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"B, N, D = tokens.shape\nkeep_ratio = 0.8\nnum_keep = int(N * keep_ratio)\n\nperm = torch.randperm(N)\nkeep_idx = perm[:num_keep]\n\nx_ctx = tokens[:, keep_idx] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.971627Z","iopub.status.idle":"2026-02-08T03:40:55.971994Z","shell.execute_reply.started":"2026-02-08T03:40:55.971795Z","shell.execute_reply":"2026-02-08T03:40:55.971818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ctx_tokens=context_encoder(x_ctx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.972926Z","iopub.status.idle":"2026-02-08T03:40:55.973547Z","shell.execute_reply.started":"2026-02-08T03:40:55.973110Z","shell.execute_reply":"2026-02-08T03:40:55.973133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"losses = []\n\nfor step in range(20):\n    optimizer.zero_grad()\n\n    # ----------------------------------\n    # 1) Get a FRESH batch & embeddings\n    # ----------------------------------\n    imgs, _ = next(iter(train_loader))\n    imgs = imgs.to(device)\n\n    tokens = patch_embed(imgs)        # [B, 196, D]\n    B, N, D = tokens.shape\n\n    # ----------------------------------\n    # 2) Random mask (JEPA-style)\n    # ----------------------------------\n    keep_ratio = 0.8\n    num_keep = int(N * keep_ratio)\n\n    perm = torch.randperm(N)\n    keep_idx = perm[:num_keep]\n    pred_idx = perm[num_keep:]\n\n    x_ctx = tokens[:, keep_idx]       # context tokens\n    y_tgt = tokens[:, pred_idx]       # target tokens (same order!)\n\n    # ----------------------------------\n    # 3) Teacher (NO grad)\n    # ----------------------------------\n    with torch.no_grad():\n        target_repr = target_encoder(y_tgt)\n\n    # ----------------------------------\n    # 4) Student\n    # ----------------------------------\n    ctx_repr = context_encoder(x_ctx)\n    pred_repr = predictor(ctx_repr)\n\n    # ----------------------------------\n    # 5) Align lengths (safe & correct)\n    # ----------------------------------\n    T = min(pred_repr.shape[1], target_repr.shape[1])\n    pred_repr   = pred_repr[:, :T]\n    target_repr = target_repr[:, :T]\n\n    # ----------------------------------\n    # 6) L2 loss in representation space\n    # ----------------------------------\n    loss = F.mse_loss(pred_repr, target_repr)\n\n    # ----------------------------------\n    # 7) Backprop ONLY student\n    # ----------------------------------\n    loss.backward()\n    optimizer.step()\n\n    # ----------------------------------\n    # 8) EMA teacher update\n    # ----------------------------------\n    ema_update(target_encoder, context_encoder, momentum=0.996)\n\n    losses.append(loss.item())\n    print(f\"Step {step}: loss = {loss.item():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:40:55.974573Z","iopub.status.idle":"2026-02-08T03:40:55.974830Z","shell.execute_reply.started":"2026-02-08T03:40:55.974724Z","shell.execute_reply":"2026-02-08T03:40:55.974738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# JEPA TOY â€” CLEAN & WORKING\n# =========================\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport random\n\n# -------------------------\n# Device\n# -------------------------\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)\n\n# -------------------------\n# Data\n# -------------------------\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\ndataset = datasets.CIFAR10(root=\".\", train=True, download=True, transform=transform)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nimgs, _ = next(iter(loader))\nimgs = imgs.to(device)\n\n# -------------------------\n# Patch Embedding\n# -------------------------\nclass PatchEmbed(nn.Module):\n    def __init__(self, patch=16, dim=256):\n        super().__init__()\n        self.proj = nn.Conv2d(3, dim, kernel_size=patch, stride=patch)\n\n    def forward(self, x):\n        x = self.proj(x)                 # [B, D, 14, 14]\n        x = x.flatten(2).transpose(1,2) # [B, 196, D]\n        return x\n\n# -------------------------\n# Tiny Transformer\n# -------------------------\nclass TinyViT(nn.Module):\n    def __init__(self, dim=256, depth=4, heads=8):\n        super().__init__()\n        layer = nn.TransformerEncoderLayer(\n            d_model=dim,\n            nhead=heads,\n            batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(layer, depth)\n\n    def forward(self, x):\n        return self.encoder(x)\n\n# -------------------------\n# JEPA Components\n# -------------------------\nDIM = 256\n\npatch_embed = PatchEmbed().to(device)\ncontext_encoder = TinyViT(DIM).to(device)\ntarget_encoder  = TinyViT(DIM).to(device)\npredictor       = TinyViT(DIM).to(device)\n\n# Freeze teacher\nfor p in target_encoder.parameters():\n    p.requires_grad = False\n\noptimizer = torch.optim.AdamW(\n    list(context_encoder.parameters()) +\n    list(predictor.parameters()),\n    lr=1e-4\n)\n\n# -------------------------\n# Random Context Mask\n# -------------------------\ndef random_context(tokens, keep_ratio=0.8):\n    B, N, D = tokens.shape\n    k = int(N * keep_ratio)\n    idx = torch.randperm(N, device=tokens.device)[:k]\n    return tokens[:, idx]\n\n# -------------------------\n# EMA Update\n# -------------------------\n@torch.no_grad()\ndef ema_update(teacher, student, m=0.996):\n    for pt, ps in zip(teacher.parameters(), student.parameters()):\n        pt.data = m * pt.data + (1 - m) * ps.data\n\n# -------------------------\n# Training Loop\n# -------------------------\nprint(\"\\nTraining...\\n\")\nfor step in range(20):\n    optimizer.zero_grad()\n\n    # Patchify\n    tokens = patch_embed(imgs)            # [B, 196, D]\n\n    # Context masking\n    x_ctx = random_context(tokens)        # [B, ~156, D]\n\n    # Student forward\n    ctx_repr = context_encoder(x_ctx)\n    pred = predictor(ctx_repr)\n\n    # Teacher forward (NO GRAD)\n    with torch.no_grad():\n        target = target_encoder(tokens)\n\n    # Shape alignment\n    T = min(pred.shape[1], target.shape[1])\n    loss = F.mse_loss(pred[:, :T], target[:, :T])\n\n    # Backprop\n    loss.backward()\n    optimizer.step()\n\n    # EMA\n    ema_update(target_encoder, context_encoder)\n\n    print(f\"Step {step:02d} | Loss: {loss.item():.4f}\")\n\nprint(\"\\nDone.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T03:45:51.504766Z","iopub.execute_input":"2026-02-08T03:45:51.505126Z","iopub.status.idle":"2026-02-08T03:45:55.666028Z","shell.execute_reply.started":"2026-02-08T03:45:51.505095Z","shell.execute_reply":"2026-02-08T03:45:55.665188Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n\nTraining...\n\nStep 00 | Loss: 1.8689\nStep 01 | Loss: 1.2484\nStep 02 | Loss: 0.9213\nStep 03 | Loss: 0.7102\nStep 04 | Loss: 0.5636\nStep 05 | Loss: 0.4562\nStep 06 | Loss: 0.3702\nStep 07 | Loss: 0.3047\nStep 08 | Loss: 0.2565\nStep 09 | Loss: 0.2226\nStep 10 | Loss: 0.1995\nStep 11 | Loss: 0.1826\nStep 12 | Loss: 0.1711\nStep 13 | Loss: 0.1645\nStep 14 | Loss: 0.1602\nStep 15 | Loss: 0.1581\nStep 16 | Loss: 0.1563\nStep 17 | Loss: 0.1551\nStep 18 | Loss: 0.1537\nStep 19 | Loss: 0.1523\n\nDone.\n","output_type":"stream"}],"execution_count":205},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}